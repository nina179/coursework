{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1910dd97-9133-41f6-849f-d8c3d209db1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lab 1 - KNN\n",
    "\n",
    "**Due: September 19th at 11:59pm**\n",
    " \n",
    "### Learning Goals:\n",
    "This first lab is intended to introduce several important machine learning concepts, libraries, and algorithms.  As with any programming assignment, you'll also be practicing and improving your general CS skills, like problem decomposition, algorithmic thinking, implementation and testing, language syntax, etc..  Here are some of the specific things you should learn while completing this assignment:\n",
    "\n",
    "* How to begin analysing a dataset to understand the real-world problem it represents\n",
    "* How to load and use the SciKit Learn library to import data and train and evaluate ML models\n",
    "* How to implement the $k$-Nearest Neighbor algorithm\n",
    "\n",
    "The assignment is presented in the form of an interactive Python notebook; it contains a mix of pre-made examples to help you understand how to do things, scaffolding with missing parts where you'll write your own code, and written short-answer questions.  Your job is to **fill in answers to the written questions** (which may require you to modify scaffolding code and re-run it, or may require you to write your own code and run it), as well as **write the indicated functions** to complete the programming portion of the assignment.  Look for the <span style=\"color:red\">TODO: ...</span> markers to help you spot places you'll need to complete things.\n",
    "\n",
    "Please be sure to ***remove* the TODO markers** as you complete each aspect (i.e. don't leave a TODO that's for something you've actually done, that's poor style because it's confusing to anyone reading your code/documentation/etc.)\n",
    "\n",
    "This lab is intended to be done with a partner (i.e. teams of two), though it can be done solo; partners will assigned based on the form you filled out (or arbitrarily if you didn't fill out the form). \n",
    "\n",
    "You'll have approximately **one week** to complete this lab, so be sure to start early and plan properly to get it all done in a timely fashion.  It's recommended that you start at the top and work your way down (i.e. the later parts are more difficult than the earlier ones). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61f8d09-7351-4e73-baa5-17c137e5c1bd",
   "metadata": {},
   "source": [
    "//# Part 1: Playing with Libraries\n",
    "\n",
    "Modify this markdown cell to add the answers to the following short-answer questions.  In doing so, consult the code cells below, which show an example of using SciKit Learn to load and classify a simple data\n",
    "set.  Note that you may need to make minor modifications to the example code for some answers (e.g. changing the number of neighbors used, running on the train vs test set).  **NOTE:** remember that to edit a markdown cell, you need to double-click on it, then change the text, and finally 'run' the cell to get the pretty formatted version.\n",
    "\n",
    "1. What is the full name of the data set used here?\n",
    "\n",
    "    Iris plants dataset (_iris_dataset)\n",
    "\n",
    "2. What sort of real-world user might be interested in a system that could successfully solve this classification problem?\n",
    "\n",
    "    A botanist, biologist, or gardner looking to classify irises for personal interest or research purposes might be interested in a system that could solve this classification problem.\n",
    "\n",
    "3. What are the stakes for this problem?  In other words, who might be hurt if the system makes a mistake?  How bad are the consequences?\n",
    "\n",
    "    This depends on what the classification was used for. If a gardener were using this find out what kinds of irises are growing in their garden, the stakes are relatively low; misclassifying an iris in this context could spread only minor misinformation. If a biologist were using this for publications or pharmaceutical researches, the stakes are higher, since it could result in research or medical accidents.\n",
    "\n",
    "4. How many _features_ (**not** including the class label) does each example in the data set have?\n",
    "\n",
    "    Four: sepal length, sepal width, petal length, petal width. \n",
    "\n",
    "5. How many _examples_ does the data set contain?\n",
    "\n",
    "    150\n",
    "\n",
    "6. What are the available class labels? Give both the encoding in the data set (i.e. the raw value) and the human-readable label associated with each value.\n",
    "\n",
    "    Iris-Setosa(0), Iris-Versicolour(1), Iris-Virginica(2)\n",
    "\n",
    "7. When run with a 60/40 train/test split, what is the accuracy of a Nearest Neighbor classifier (i.e. $k=1$) on the _testing set_?\n",
    "    \n",
    "   0.9166666666666666\n",
    "\n",
    "8. Accuracy of 3-nearest neighbor?\n",
    "\n",
    "    0.9333333333333333\n",
    "\n",
    "9. Accuracy of 5-nearest neighbor?\n",
    "\n",
    "    0.95\n",
    "\n",
    "10. Accuracy of 20-nearest neighbor?\n",
    "\n",
    "    0.9166666666666666\n",
    "\n",
    "11. Accuracy of 40-nearest neighbor?\n",
    "\n",
    "    0.8666666666666667\n",
    "\n",
    "12. Accuracy of 80-nearest neighbor?\n",
    "\n",
    "    0.6\n",
    "\n",
    "13. What is the accuracy of nearest neighbor ($k=1$) on the _training set_ (*not* the testing set)?\n",
    "\n",
    "    100%\n",
    "\n",
    "14. Is there a difference between the accuracy on the _training set_ and accuracy on the _testing set_?  Explain why the observed behavior occurs.\n",
    "    \n",
    "    Yes, the accuracy on the _training set_ will always be 100% while the accuracy on the _testing set_ may differ. If we evaluate the accuracy of the KNN ($k=1$) model based on its training set, the nearest neighbor of each query point is always itself, since it is recorded as one of the training point. Therefore, the algorithm always returns the label of itself, resulting an overall prediction accurary of 100% and has no indication on whether this algorithm could perform well on a novel query point. On the other hand, since the _testing set_ might contain query points novel to the model, there is no guarentee to the accuracy due to noise in data, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d1784c4-1cbc-4d2d-9723-7b2042f15e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries we'll need...\n",
    "import numpy as np     # the data we'll be loading is in the form of numpy arrays \n",
    "from sklearn import datasets  # here we grab a module from the SciKit-Learn library that contains example data sets\n",
    "from sklearn import neighbors # this module contains an implementation of a KNN classifier\n",
    "from sklearn.model_selection import train_test_split  # and here we get one method from the model_selection module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1604f53a-371e-4226-afa8-bfd40c76da6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# once we've imported the 'datasets' module, we can use it to load some data...\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c6686b8-1672-4aac-9b63-865a02c93a48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# let's check out the description:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(iris\u001b[38;5;241m.\u001b[39mDESCR)\u001b[38;5;66;03m# Split the data into training and testing sets\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mX\u001b[49m, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# let's check out the description:\n",
    "print(iris.DESCR)# Split the data into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa1e35b2-98fb-4541-ac64-444c22c6aacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see what it looks like\n",
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "847500ea-afba-4fc9-acea-9fc1ecd5d471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7853b66e-4e2a-42e0-96be-e1c07b76ea04",
   "metadata": {},
   "source": [
    "**Note:** this next cell produces a very long output! If you don't want to look at it, you can click the blue bar to the left of a cell to collapse it (i.e. hide it from view until you click the blue bar again to expand it).  After examining the output of this cell, it's recommended that you collapse it so you don't have to scroll past the whole thing repeatedly.  You may want to do this with some other cells as well (e.g. the data description from above may similarly be annoying to scroll past, so you may want to hide it when you're not using it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c39a26-6076-4837-8053-1960184a43c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e52722-361a-4127-85f2-d6e6699c1d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13117998-8234-4f07-b4c9-95af5496959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that we can index into our data set to get a single example:\n",
    "iris.data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500b47b0-9afd-44b9-afa6-e74417ee691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's train a nearest neighbor classifier...\n",
    "# note that we can use the parameter 'n_neighbors' to control the \"K\" in our KNN\n",
    "classifierA = neighbors.KNeighborsClassifier(metric='euclidean', n_neighbors=1)\n",
    "classifierA.fit(iris.data, iris.target) # this step trains classifierA with the data and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27be3777-9315-4d54-a8d8-7267d9d12c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...then test it out to see how it performs (the result is the percentage of examples it gets right)\n",
    "classifierA.score(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c91517-39b8-40e1-b2d2-9cb72b55ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...hmm, that seems too good to be true; probably because we used the same data for training and testing! \n",
    "# Lets try splitting our data into two parts so we can get a more realistic idea of how this would work.\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4, random_state=0)\n",
    "\n",
    "print(\"training shape:\", X_train.shape, \", testing shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f60214-180a-4591-bb47-f98e30131445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can re-train our classifier using just the \"training\" part of the data:\n",
    "# note: you'll need to modify this cell in different ways to answer questions 8-12\n",
    "classifierB = neighbors.KNeighborsClassifier(metric='euclidean', n_neighbors=1)\n",
    "classifierB.fit(X_train, y_train)\n",
    "print(\"true accuracy: \", str(classifierB.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16252971-99b6-4526-a076-4cacdc5d6a08",
   "metadata": {},
   "source": [
    "accuracy:  0.9166666666666666***\n",
    "Note that SciKit learn has quite good documentation, so if you'd like to know more information about how to use these methods (e.g. what parameters are available, what do they do, etc.) you can look them up fairly easily.  Generally, a google search for `sklearn <myMethod>` will give you a link to the docs within the first couple of hits.\n",
    "\n",
    "Note also that the sklearn documentation is broken into two parts, the [Users Guide](https://scikit-learn.org/stable/user_guide.html) and the [API](https://scikit-learn.org/stable/modules/classes.html) Reference; the former is written more like a textbook, and contains long-form explanations and examples, while the latter is a more typical API reference with complete and detailed explanations of tha interface for each class and method.  The two are also cross-linked; pretty much every page in the API has a link to the relevant Users Guide page, and each mention of a class or method in the Users Guide is a link to the API.\n",
    "\n",
    "For instance, here's the user's guide page on KNNs: https://scikit-learn.org/stable/modules/neighbors.html\n",
    "\n",
    "And here's the API page for KNeighborsClassifier: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\n",
    "You'll typically want to refer to _both_ of them to get a full understanding of how to use a given module from the library.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7eb9f0-03c0-4299-8cba-488fa79bd7fc",
   "metadata": {},
   "source": [
    "# Part 2: Nearest Neighbor from Scratch\n",
    "\n",
    "This part of this assignment asks you to implement your own Nearest Neighbor classifier.  Youâ€™ve already got scaffolding (above) that shows how to use the Nearest Neighbor classifier from the toolkit. Your job is to write your own nearest neighbor classifier, which _should_ give the same answer as the one from Scikit Learn.  Here's a recommended development plan:\n",
    "\n",
    "1. Implement the `distance()` function to compute the distance between two examples, then test it to be sure it works correctly\n",
    "1. Implement and test the `nearestNeighbor()` function to find the nearest example to a single novel query\n",
    "1. Implement and test the `testNearestNeighbor()` function to apply nearestNeighbor to each example in a labeled test set and compute the accuracy of your nearest neighbor classifier\n",
    "1. Extend your nearest neighbor classifier to a full $k$-nearest neighbor classifier\n",
    "1. Finally, go back and refactor and/or optimize your code as necessary\n",
    "\n",
    "\n",
    "For this course, we're not worried about low-level optimization (i.e. the kind of stuff you might do in C or C++), but we _are_ concerned about big-O efficiency.  Correctness is far more important than efficiency, but efficiency shouldn't be completely ignored either.  For instance, if your implementation is incorrect (i.e. does not work) you'll loose a lot of points.  If your implementation gives the correct result but it's $O(n)$ in space when it should be $O(1)$, or $O(n^2)$ time when it should be $O(n)$, you'll loose a few points.\n",
    "\n",
    "As a result, you should always start out by implementing an algorithm in the simplest way possible, even if it's less efficient, since you're less likely to make mistakes when writing a simple solution as compared to a complex one.  Then, once you've got a working baseline, you can try to improve it and make sure the behavior doesn't change (i.e. you can tell easily if your \"optimization\" ends up breaking something).\n",
    "\n",
    "For this assignment, detailed descriptions of each aspect of the development plan are given in the cells below, along with recommended prototypes for the functions described."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6df77c-aa79-44a8-9de9-abcbf1fdac76",
   "metadata": {},
   "source": [
    "/ ******\n",
    "### Distance\n",
    "\n",
    "* The `distance()` function should take two inputs (you can assume each will be an indexable collection of numbers, e.g. a list or numpy array), and return the Euclidean distance between them.  \n",
    "\n",
    "* Recall that Euclidean distance (also called the $L^2$-norm) between two $d$ dimensional vectors $\\vec{a}$ and $\\vec{b}$ is calculated as: $$| \\vec{a} - \\vec{b}|_2 = \\sqrt{\\sum_{i=1}^d (a_i - b_i)^2}$$\n",
    "\n",
    "* Remember that the $\\sum$ in math notation translates to an accumulator-pattern for-loop in code, and that the sub-script indexing in math notation ($x_i$) translates to array-style indexing (`x[i]`).\n",
    "\n",
    "* Note that this function should be able to handle input vectors of any length (e.g. it should handle distances in any Cartesian space, regardless of how many dimensions it has, so long as the two inputs are the same length as each other); don't just hard-code it to handle the particular properties of the data set we happen to be using for testing.\n",
    "\n",
    "* Note also that while the mathematical notation goes from 1 to $d$, you'll likely want your code to include a loop from 0 to $(d-1)$.  This is because mathematicians tend to index starting at 1, but computer scientists tend to index starting at 0.  This sort of thing is a frequent source of off-by-one errors when converting from math notation to code notation, so keep an eye out for it going forward.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba7aa7c-11a2-4a85-ad5f-bb6f59fe1461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# note that the lack of types in Python means argument types can be confusing;\n",
    "# in this case, 'a' and 'b' should be arrays, and the function should compute Euclidean distance between them,\n",
    "# which should be returned as a scalar\n",
    "\n",
    "from math import sqrt  # you may want to use this function for calculating Euclidean distance;\n",
    "                       # alternatively, you can try raising something to the power of 0.5\n",
    "\n",
    "def distance(a, b):    \n",
    "    summation = 0\n",
    "    for i in range(len(a)):\n",
    "        summation += (a[i] - b[i])**2\n",
    "        \n",
    "    dist = sqrt(summation)\n",
    "    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36856fa3-43b2-4071-b930-5d89f4316aa8",
   "metadata": {},
   "source": [
    "#### Testing Distance\n",
    "\n",
    "- Test the distance function thoroughly to be sure it works as intended.  \n",
    "\n",
    "- Be sure to do some basic error-checking \n",
    "    - remember Python does auto-typing, which means the type-checker won't catch errors for you \n",
    "    - e.g. in this case if the two inputs aren't both one-dimensional lists/arrays of numbers, or don't have the same number of elements, that's a problem the user should be alerted to right away, but Python won't automatically catch it\n",
    "    - having your code check for and report errors this will save you headaches later on when debugging code that calls this function.\n",
    "    - make sure that whatever error messages get produced are **helpful and informative** so that they actually make later debuggin easier; just having the program crash with no info isn't very helpful (though it's still better than continuing to run and silently propogating errors that pop up elsewhere).\n",
    "\n",
    "    - remember that there are several ways of indicating an error to the user; simply printing an obvious error message and returning a 'dummy' value is one way.  An alternative is throwing an exception.\n",
    "\n",
    "Here's a few examples of simple tests to get you started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed402b4-4a15-4aab-bc6c-b421a585d40b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def checkError (a, b):\n",
    "    if not type(a) == type(b):\n",
    "        raise TypeError(\"a and b must be of the same type\")\n",
    "        return\n",
    "    if not len(a) == len(b):\n",
    "        raise TypeError(\"a and b must be of the same length\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117808b4-5cfe-433f-896c-6b4d3c107f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check this result by hand to make sure your distance function works; \n",
    "# then check it using some other point pairs to be sure\n",
    "a = [0,0]\n",
    "b = [3,2]\n",
    "print(f\"a = {a}\")\n",
    "print(f\"b = {b}\")\n",
    "checkError(a, b)\n",
    "d = distance(a, b)\n",
    "print(f\"calculated distance between (a, b) = {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca555a57-51ae-41e4-9b53-168c2a2af3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's another test using the first two points from the training data;\n",
    "# again, check the result by hand to make sure your function works correctly\n",
    "a = X_train[0]\n",
    "b = X_train[1]\n",
    "print(f\"a = {a}\")\n",
    "print(f\"b = {b}\")\n",
    "checkError(a, b)\n",
    "d = distance(a, b)\n",
    "print(f\"distance between (a, b) = {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8c6697-d3cd-4609-86d5-0022eed1131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some tests to see what happens if we call the function on different length inputs\n",
    "# NOTE that other than the first example, the rest of these SHOULD produce some sort of\n",
    "# noticable error message, since the distance function is only well defined for\n",
    "# inputs of the same length\n",
    "for (a, b) in [ ([0, 1], [2, 3]), (1, [2, 3]), ([1, 2], \"hello\"), ([1, 2], [[1,2], [2, 3], [3, 4]]) ]:\n",
    "    print(f\"for a: {a}, b: {b}\")\n",
    "    try:\n",
    "        checkError(a, b)\n",
    "        d = distance(a, b)\n",
    "        print(f\"distance between (a, b) = {d}\")\n",
    "    except Exception as e:\n",
    "        print(f\"!!Exception: {e}\")\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0627902-1c53-404f-9424-ae68534e8a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (a, b) in [([0, 0], [0,2]), ([1,2,3,4], [1,2,5,6]), ([0, 1, 3], [9, 8]) ]:\n",
    "    print(f\"for a: {a}, b: {b}\")\n",
    "    try:\n",
    "        checkError(a, b)\n",
    "        d = distance(a, b)\n",
    "        print(f\"distance between (a, b) = {d}\")\n",
    "    except Exception as e:\n",
    "        print(f\"!!Exception: {e}\")\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d47c05-7579-453f-8a5d-575fd3bb6873",
   "metadata": {},
   "source": [
    "### Nearest Neighbor\n",
    "- The `nearestNeighbor()` function should take in a set of training examples (both features and labels), as well as a novel query point, and return the label of the point in the training set closest to the novel query point.\n",
    "\n",
    "- Be sure your function returns the *label* of the winning point, not the distance to that point or the coordinates of the point itself\n",
    "\n",
    "- You should make use of the `distance()` function you wrote above\n",
    "\n",
    "- You may also create additional helper functions if you want\n",
    "\n",
    "- You _may_ use library functions if you want, so long as they aren't shortcuts around the learning process (i.e.  don't make assumptions that trivialize the assignment)\n",
    "\n",
    "- On the other hand, you shouldn't _need_ to use any library functions, and properly written the function is pretty short even without them (my reference implementation is 8 lines)\n",
    "\n",
    "- Note that there are several ways to solve this problem, but not all are equally computationally efficient.  It can be done in $O(1)$ space (discounting the size of the inputs) and $O(n)$ time.  \n",
    "  - if you use helper functions or library functions, also keep in mind their efficiency; e.g. if you use Python's built-in `sort()` function, your runtime will be **at best** $O(n \\log(n))$ regardless of what you put in your own function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb106b63-473a-4078-8944-4363898ec529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function should return the training label associated with the training \n",
    "\n",
    "def nearestNeighbor(train, trainLabels, query):\n",
    "    # train = set of data assocaited with each reference\n",
    "    # trainLabels = what type of iris\n",
    "    # query = flower we're trying to get\n",
    "    \n",
    "    # find label of the neighbor that has the smallest distance to query\n",
    "    minDist = distance(train[0], query)\n",
    "    label = trainLabels[0]\n",
    "    \n",
    "    for i in range(1, len(train)):\n",
    "        currDist = distance(train[i], query)\n",
    "        if currDist < minDist:\n",
    "            minDist = currDist\n",
    "            label = trainLabels[i]\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158ba842-7b51-46af-9d6d-5570bc12adc9",
   "metadata": {},
   "source": [
    " #### Tests for Nearest Neighbor\n",
    "- Again, be sure to test this function and ensure it works correctly before moving on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e727bfd-c347-4bf0-b1b6-7d053f4f3e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code for nearestNeighbor\n",
    "# the data points and their labels that we would use to train our model\n",
    "train = ([15.1, 3.5, 1.4, 0.2],\n",
    "       [20.9, 3.0, 1.4, 0.2],\n",
    "       [4.7, 13.2, 1.3, 0.2],\n",
    "       [300.6, 9.32, 1.5, 0.2],\n",
    "       [7.0, 1.2, 1.9, 0.2],\n",
    "       [0.4, 3.9, 1.7, 0.4])\n",
    "\n",
    "trainLabels = ([1, 0, 3, 4, 2, 5])\n",
    "\n",
    "# as each of the query point is designed to be nearest to only one of the training points, we anticipate them to be labelled as 1, 0, 3, 4, 2, 5.\n",
    "queryList = ([15, 3.5, 1.4, 0.2],\n",
    "       [21, 3.0, 1.4, 0.2],\n",
    "       [4.8, 13.1, 1.3, 0.2],\n",
    "       [300, 9.32, 1.5, 0.2],\n",
    "       [7.0, 1.2, 1.8, 0.1],\n",
    "       [0.4, 4, 1.7, 0.4])\n",
    "\n",
    "for vector in queryList:\n",
    "    print(f\"nearest neighbor of {vector} is: \" + str(nearestNeighbor(train, trainLabels, vector)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19e72b3-56e3-42f9-a5ef-7828775ddc1d",
   "metadata": {},
   "source": [
    "  ***\n",
    "### Evaluating a Nearest Neighbor classifier\n",
    "- Define the `testNearestNeighborClassifier()` function to take 4 inputs: training data, training labels, testing data, and testing labels. \n",
    "\n",
    "- Fill in the body of this function so that it loops over the examples in the test set, and for each one performs a nearest-neighbor classification. \n",
    "\n",
    "- The function should print out the overall accuracy (i.e. the number of times the predicted label matched the true label for the testing examples, divided by the total number of testing examples). \n",
    "\n",
    "- This function should make use of the helper functions you wrote in the previous steps.\n",
    "\n",
    "- Again, note that you may create additional helper functions if you wish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c51de-51fb-4509-8455-ca794e1884cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function should print the average accuracy of a nearest neighbor classifier \n",
    "#      applied to each of the test points\n",
    "def testNearestNeighborClassifier(train, trainLabels, test, testLabels):\n",
    "    # predict the label of each test query point\n",
    "    predictedLabels = []\n",
    "    for query in test:\n",
    "        predictedLabel = nearestNeighbor(train, trainLabels, query)\n",
    "        predictedLabels.append(predictedLabel)\n",
    "    \n",
    "    # calculate accuray\n",
    "    count = 0\n",
    "    for i in range(len(testLabels)):\n",
    "        if predictedLabels[i] == testLabels[i]:\n",
    "            count += 1\n",
    "    accuracy = count / len(testLabels)\n",
    "    \n",
    "    print(\"test accuracy: \", str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0728d0-64ac-4ba2-89ae-fce82f19b87f",
   "metadata": {},
   "source": [
    "#### Testing nearest neighbor classifier\n",
    "- Test this function on the same train/test data you used with the SciKit Learn nearest neighbor classifier; your function should produce the same accuracy as the version from the toolkit (at least to the first few significant figures)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c179db2-7adb-4880-92fa-33a87bbaf7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that this should give you the same value as the library implementation of \n",
    "# KNeighborsClassifier with n_neighbors=1\n",
    "testNearestNeighborClassifier(X_train, y_train, X_test, y_test)\n",
    "\n",
    "classifierB = neighbors.KNeighborsClassifier(metric='euclidean', n_neighbors=1)\n",
    "classifierB.fit(X_train, y_train)\n",
    "print(\"sklearn accuracy: \", str(classifierB.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ee7b94-435a-4e13-b223-fae4fc4d85b2",
   "metadata": {},
   "source": [
    "***\n",
    "### K Nearest Neighbor classifier\n",
    "\n",
    "- Now that you've done the basic single-nearest neighbor, implement $k$-nearest neighbors below\n",
    "\n",
    "- Create the function`testKNearestNeighborClassifier()` to take a number of neighbors as a parameter, in addition to the four parameters you used above. \n",
    "\n",
    "- You may want to start by copying your code from above and modifying it\n",
    "\n",
    "- You'll likely want to create some new helper functions for this as well (e.g. `kNearestNeighbor()` as an analog to the `nearestNeighbor()` you wrote above)\n",
    "\n",
    "- You can add as many cells and/or helper functions as you like; be sure to test these helper functions too.\n",
    "\n",
    "- You may also want to look at the documentation for `numpy`, as it has some functions that you might find helpful.  \n",
    "\n",
    "- Once again, an _efficient_ implementation of `kNearestNeighbor()` (i.e. finding the label for one example) should be linear time in $n$ and constant space (though the constant here will be $k$ times what it was for the earlier version of `nearestNeighbor()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c81fd58-0458-4337-8d12-03d800713353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def kNearestNeighbor1(train, trainLabels, query, k):\n",
    "    # solution 1 : with heap. time complexity: O(n), space complexity: O(n)\n",
    "    \n",
    "    # pairs up distances with labels, time: O(n), space: O(n)\n",
    "    neighbors = []\n",
    "    for i in range(len(train)):\n",
    "        currDist = distance(train[i], query)\n",
    "        neighbors.append((currDist, trainLabels[i]))\n",
    "    \n",
    "    # get k nearest neighbor from heap\n",
    "    heapq.heapify(neighbors)\n",
    "    kNearest = heapq.nsmallest(k, neighbors, key=None)\n",
    "    \n",
    "    # get labels of neighbors\n",
    "    nearestLabels = [n[1] for n in kNearest]\n",
    "    \n",
    "    return nearestLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c366d55-a89c-4f33-8a1f-a33b9d47460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def kNearestNeighbor2(train, trainLabels, query, k):\n",
    "    # solution 2 : with array. time complexity: O(n), space complexity: O(k)\n",
    "    \n",
    "    kNeighbors = np.zeros((k, 2))\n",
    "    \n",
    "    # go through each of the training points and only record the ones that have k smallest distance\n",
    "    n = 0 # tracks the number of items added in the array\n",
    "    for i in range(len(train)):\n",
    "        currDist = distance(train[i], query)\n",
    "        # the if else bolck ensures only the smallest k distances are recorded in the array\n",
    "        if (n < k):\n",
    "            kNeighbors[n] =  [currDist, trainLabels[i]]\n",
    "            n += 1\n",
    "            # kNeighbors = np.append(kNeighbors, [currDist, trainLabels[i]])\n",
    "        elif (currDist < kNeighbors[: , 0].max()):\n",
    "            idxReplace = kNeighbors[: , 0].argmax(axis=0)\n",
    "            kNeighbors[idxReplace] = [currDist, trainLabels[i]]\n",
    "\n",
    "    nearestLabels = (kNeighbors[: , 1]).astype('int64') # slice the 2D array to only preserve labels, i.e. the second column\n",
    "    return nearestLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e8817e-c0ac-44da-9656-831fbff94123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testKNN():\n",
    "    # the training points and their labels\n",
    "    train = ([300.1, 3.5, 1.4, 0.2], # 0\n",
    "       [300.9, 3.5, 1.4, 0.2], # 1\n",
    "       [4.7, 13.2, 7000, 0.2], # 2\n",
    "       [300.6, 9.32, 1.5, 0.2], # 3\n",
    "       [.0, 1.2, 7000, 0.2], # 4\n",
    "       [0.4, 3.9, 7000, 0.4], # 5 \n",
    "       [0.4, 3.9, 7100, 0.4]) # 6 \n",
    "\n",
    "    trainLabels = ([1, 6, 3, 4, 5, 10, 2])\n",
    "    \n",
    "    # as the query points are designed to be significantly closer to some training points than to the others, the labels of their nearest neighbors are listed below\n",
    "    queryList = ([300, 3.5, 1.4, 0.2],   # closest to #0, #1, #3 (not listed by distance)\n",
    "           [20.9, 3.0, 7000, 0.2])   # closest to  #2, #4, #5, #6 (not listed by distance)\n",
    "\n",
    "    for vector in queryList:\n",
    "        for k in range(1, 4):\n",
    "            print(f\"1. labels of the {k} nearest neighbor of {vector} are \" + str(kNearestNeighbor1(train, trainLabels, vector, k)))\n",
    "            print(f\"2. labels of the {k} nearest neighbor of {vector} are \" + str(kNearestNeighbor2(train, trainLabels, vector, k)))\n",
    "        print(\"-----\")\n",
    "\n",
    "testKNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7afeef-c75e-4f9b-b810-362b12968af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function tests k nearest neighbor classifier\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def testKNearestNeighborClassifier(train, trainLabels, test, testLabels, k):\n",
    "    predictedLabels = []\n",
    "    for query in test:\n",
    "        neighbors = kNearestNeighbor2(train, trainLabels, query, k) # get the labels of neighbors\n",
    "        np_neighbors = np.array(neighbors)\n",
    "        nLabel = np.bincount(np_neighbors).argmax() # get the pluraity vote from the labels\n",
    "        predictedLabels.append(nLabel) # append the vote to a list for accuracy test later\n",
    "    \n",
    "    # count how many of our label matches the actual label and calculate the accuracy\n",
    "    count = 0\n",
    "    for i in range(len(predictedLabels)):\n",
    "        if predictedLabels[i] == testLabels[i]:\n",
    "            count += 1\n",
    "    \n",
    "    acc = count / len(testLabels)\n",
    "    print(\"test accuracy: \", str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f89e96-bfaf-486d-86a9-46a8c8bd3e76",
   "metadata": {},
   "source": [
    "#### Testing K nearest neighbor\n",
    "\n",
    "- Again, you should be able to test this function by running it with different numbers of neighbors, and you should  get the same results as you would with SciKit Learn, modulo possible tie-breaking issues \n",
    "    - (i.e. for some values of $k$ your code may be 'correct' and still return a different value than sklearn if you use a different method to resolve voting ties than the library does; this is especially likely for even values of $k$). \n",
    "\n",
    "- You may also want to print `X_train`, `y_train`, `X_test`, and `y_test` to look at them and make sure you understand what they contain (and how they are formatted)\n",
    "\n",
    "- Note that this function should give you the same result for k=1 that your previous nearest neighbor code gives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb98b5d-db99-4115-bbd0-6a4bca59185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# again, you can test against the lirbary for other values of k, though keep in \n",
    "# mind that the library might do tie breaking differently, so you can get different \n",
    "# results even with a \"correct\" algorithm, particularly for even values of K\n",
    "k_values = [1, 3, 5, 20, 40, 80]\n",
    "for k in k_values:\n",
    "    \n",
    "    classifierB.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"when k = \", k) # print k\n",
    "    # print our algorithm's accuracy\n",
    "    testKNearestNeighborClassifier(X_train, y_train, X_test, y_test, k)\n",
    "    \n",
    "    # print SciKit accuracy\n",
    "    classifierB = neighbors.KNeighborsClassifier(metric='euclidean', n_neighbors=k)\n",
    "    classifierB.fit(X_train, y_train)\n",
    "    trueAccuracy = classifierB.score(X_test, y_test)\n",
    "    print(\"sklearn accuracy: \", trueAccuracy)\n",
    "    \n",
    "    print(\"-----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
